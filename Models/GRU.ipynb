{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv9n6KDV_LNx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/College/Semester 5/NLP Project/NLP_Project-main/NLP_Project-main/Data/PreprocessedData/train_preprocessed.csv')"
      ],
      "metadata": {
        "id": "1NqF_nTI__mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = pd.read_csv('/content/drive/MyDrive/College/Semester 5/NLP Project/NLP_Project-main/NLP_Project-main/Data/PreprocessedData/val_preprocessed.csv')"
      ],
      "metadata": {
        "id": "5vX0PqkuFnW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_df['preprocessed_text'].to_list()\n",
        "train_Y = (train_df['label'].replace('OFF',1)).replace('NOT', 0).to_list()"
      ],
      "metadata": {
        "id": "0wOkywr8AoAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_X = val_df['preprocessed_text'].to_list()\n",
        "val_Y = (val_df['label'].replace('OFF',1)).replace('NOT', 0).to_list()"
      ],
      "metadata": {
        "id": "SQVD42IOFsTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 10000\n",
        "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_X)"
      ],
      "metadata": {
        "id": "PDON32E3_-5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=128,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.GRU(64),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "ISROsum6_Nrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(0.0001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "j3KXwSFDDZ6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6QYHxhKLtCU",
        "outputId": "67414601-ae34-4229-c8d7-49b735645677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, None)             0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,473\n",
            "Trainable params: 1,321,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x = train_X, y = train_Y, epochs=10,\n",
        "                    validation_data=(val_X, val_Y),\n",
        "                    validation_steps=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpw0EcpiE4dn",
        "outputId": "41f9a4be-5e55-484c-a177-d806e206c770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "331/331 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 0.6710"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r331/331 [==============================] - 25s 61ms/step - loss: 0.6474 - accuracy: 0.6710 - val_loss: 0.6286 - val_accuracy: 0.6545\n",
            "Epoch 2/10\n",
            "331/331 [==============================] - 17s 53ms/step - loss: 0.5838 - accuracy: 0.6712\n",
            "Epoch 3/10\n",
            "331/331 [==============================] - 22s 65ms/step - loss: 0.4594 - accuracy: 0.7685\n",
            "Epoch 4/10\n",
            "331/331 [==============================] - 18s 53ms/step - loss: 0.3369 - accuracy: 0.8592\n",
            "Epoch 5/10\n",
            "331/331 [==============================] - 18s 54ms/step - loss: 0.2671 - accuracy: 0.8934\n",
            "Epoch 6/10\n",
            "331/331 [==============================] - 17s 53ms/step - loss: 0.2160 - accuracy: 0.9176\n",
            "Epoch 7/10\n",
            "331/331 [==============================] - 17s 52ms/step - loss: 0.1812 - accuracy: 0.9339\n",
            "Epoch 8/10\n",
            "331/331 [==============================] - 18s 53ms/step - loss: 0.1529 - accuracy: 0.9482\n",
            "Epoch 9/10\n",
            "331/331 [==============================] - 17s 53ms/step - loss: 0.1335 - accuracy: 0.9542\n",
            "Epoch 10/10\n",
            "331/331 [==============================] - 18s 54ms/step - loss: 0.1150 - accuracy: 0.9617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = model.predict(train_X)\n",
        "val_pred = model.predict(val_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5XV2x_ZIQ_9",
        "outputId": "ff665885-456c-493d-fafb-169551b55db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "331/331 [==============================] - 5s 11ms/step\n",
            "83/83 [==============================] - 2s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = np.where(train_pred > 0.5, 1, 0)\n",
        "val_pred = np.where(val_pred > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "OGQJ1wW1sxYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def computeAllScores(y_pred_train, y_pred_dev, train_labels, dev_labels):\n",
        "    print(\"Accuracy Train: \", accuracy_score(train_labels, y_pred_train))\n",
        "    print(\"Accuracy Dev: \", accuracy_score(dev_labels, y_pred_dev))\n",
        "    print(\"Weighted F1 Train: \", f1_score(train_labels, y_pred_train, average='weighted'))\n",
        "    print(\"Weighted F1 Dev: \", f1_score(dev_labels, y_pred_dev, average='weighted'))\n",
        "    print(\"Macro F1 Train: \", f1_score(train_labels, y_pred_train, average='macro'))\n",
        "    print(\"Macro F1 Dev: \", f1_score(dev_labels, y_pred_dev, average='macro'))\n",
        "    print(\"Micro F1 Train: \", f1_score(train_labels, y_pred_train, average='micro'))\n",
        "    print(\"Micro F1 Dev: \", f1_score(dev_labels, y_pred_dev, average='micro'))\n",
        "    print(\"Weighted Recall Train: \", recall_score(train_labels, y_pred_train, average='weighted'))\n",
        "    print(\"Weighted Recall Dev: \", recall_score(dev_labels, y_pred_dev, average='weighted'))\n",
        "    print(\"Macro Recall Train: \", recall_score(train_labels, y_pred_train, average='macro'))\n",
        "    print(\"Macro Recall Dev: \", recall_score(dev_labels, y_pred_dev, average='macro'))\n",
        "    print(\"Micro Recall Train: \", recall_score(train_labels, y_pred_train, average='micro'))\n",
        "    print(\"Micro Recall Dev: \", recall_score(dev_labels, y_pred_dev, average='micro'))\n",
        "    # Confusion Matrix\n",
        "    print(\"Confusion Matrix Train: \")\n",
        "    print(confusion_matrix(train_labels, y_pred_train))\n",
        "    print(\"Confusion Matrix Dev: \")\n",
        "    print(confusion_matrix(dev_labels, y_pred_dev))"
      ],
      "metadata": {
        "id": "O-0Gp7t-rDo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "computeAllScores(train_pred, val_pred, train_Y, val_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV_jxJygrzy_",
        "outputId": "5c0983cf-e13c-4f65-b995-93fc321d3c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train:  0.9705438066465257\n",
            "Accuracy Dev:  0.7246978851963746\n",
            "Weighted F1 Train:  0.9703997195562272\n",
            "Weighted F1 Dev:  0.7176376889199447\n",
            "Macro F1 Train:  0.9663225051729393\n",
            "Macro F1 Dev:  0.681315421283972\n",
            "Micro F1 Train:  0.9705438066465257\n",
            "Micro F1 Dev:  0.7246978851963745\n",
            "Weighted Recall Train:  0.9705438066465257\n",
            "Weighted Recall Dev:  0.7246978851963746\n",
            "Macro Recall Train:  0.9619636630403997\n",
            "Macro Recall Dev:  0.6751496977665945\n",
            "Micro Recall Train:  0.9705438066465257\n",
            "Micro Recall Dev:  0.7246978851963746\n",
            "Confusion Matrix Train: \n",
            "[[7015   92]\n",
            " [ 220 3265]]\n",
            "Confusion Matrix Dev: \n",
            "[[1448  285]\n",
            " [ 444  471]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_pred = np.where(val_pred > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "XW70dHlDIH37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(val_Y, val_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTYFXI0AHgh_",
        "outputId": "fd1a044f-2375-4dbe-aeb6-56b8ce614888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6926490155178788"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_X)/len(val_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDoR2vp9Icyx",
        "outputId": "31e4557d-793f-4a6a-9daf-b796867799f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-pFAU0Fbytd",
        "outputId": "be2657a1-b4e8-4496-8a09-7a91cd16b7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2648"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "np414M7eb0aY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}