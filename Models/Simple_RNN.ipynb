{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Vv9n6KDV_LNx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/College/Semester 5/NLP Project/NLP_Project-main/NLP_Project-main/Data/PreprocessedData/train_preprocessed.csv')"
      ],
      "metadata": {
        "id": "1NqF_nTI__mz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = pd.read_csv('/content/drive/MyDrive/College/Semester 5/NLP Project/NLP_Project-main/NLP_Project-main/Data/PreprocessedData/val_preprocessed.csv')"
      ],
      "metadata": {
        "id": "5vX0PqkuFnW7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_df['preprocessed_text'].to_list()\n",
        "train_Y = (train_df['label'].replace('OFF',1)).replace('NOT', 0).to_list()"
      ],
      "metadata": {
        "id": "0wOkywr8AoAd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_X = val_df['preprocessed_text'].to_list()\n",
        "val_Y = (val_df['label'].replace('OFF',1)).replace('NOT', 0).to_list()"
      ],
      "metadata": {
        "id": "SQVD42IOFsTM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 10000\n",
        "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_X)"
      ],
      "metadata": {
        "id": "PDON32E3_-5U"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=128,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.SimpleRNN(64),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "ISROsum6_Nrq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(0.0001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "j3KXwSFDDZ6N"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6QYHxhKLtCU",
        "outputId": "05a06115-955d-498d-98c4-e040ceec9986"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_1 (TextV  (None, None)             0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 64)                12352     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,577\n",
            "Trainable params: 1,296,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x = train_X, y = train_Y, epochs=10,\n",
        "                    validation_data=(val_X, val_Y),\n",
        "                    validation_steps=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpw0EcpiE4dn",
        "outputId": "f6c6d441-e50c-4afa-a126-dc8d6496798d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "331/331 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.6710"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r331/331 [==============================] - 19s 53ms/step - loss: 0.6377 - accuracy: 0.6710 - val_loss: 0.6249 - val_accuracy: 0.6545\n",
            "Epoch 2/10\n",
            "331/331 [==============================] - 13s 38ms/step - loss: 0.5635 - accuracy: 0.6795\n",
            "Epoch 3/10\n",
            "331/331 [==============================] - 13s 38ms/step - loss: 0.4184 - accuracy: 0.7905\n",
            "Epoch 4/10\n",
            "331/331 [==============================] - 13s 38ms/step - loss: 0.2766 - accuracy: 0.8792\n",
            "Epoch 5/10\n",
            "331/331 [==============================] - 13s 38ms/step - loss: 0.1785 - accuracy: 0.9301\n",
            "Epoch 6/10\n",
            "331/331 [==============================] - 13s 38ms/step - loss: 0.1224 - accuracy: 0.9536\n",
            "Epoch 7/10\n",
            "331/331 [==============================] - 13s 40ms/step - loss: 0.0875 - accuracy: 0.9695\n",
            "Epoch 8/10\n",
            "331/331 [==============================] - 13s 38ms/step - loss: 0.0694 - accuracy: 0.9751\n",
            "Epoch 9/10\n",
            "331/331 [==============================] - 14s 43ms/step - loss: 0.0551 - accuracy: 0.9821\n",
            "Epoch 10/10\n",
            "331/331 [==============================] - 13s 39ms/step - loss: 0.0470 - accuracy: 0.9856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = model.predict(train_X)\n",
        "val_pred = model.predict(val_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5XV2x_ZIQ_9",
        "outputId": "e8ddf521-59b5-4ff5-dbf9-503d3f711fe3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "331/331 [==============================] - 3s 8ms/step\n",
            "83/83 [==============================] - 1s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = np.where(train_pred > 0.5, 1, 0)\n",
        "val_pred = np.where(val_pred > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "OGQJ1wW1sxYV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def computeAllScores(y_pred_train, y_pred_dev, train_labels, dev_labels):\n",
        "    print(\"Accuracy Train: \", accuracy_score(train_labels, y_pred_train))\n",
        "    print(\"Accuracy Dev: \", accuracy_score(dev_labels, y_pred_dev))\n",
        "    print(\"Weighted F1 Train: \", f1_score(train_labels, y_pred_train, average='weighted'))\n",
        "    print(\"Weighted F1 Dev: \", f1_score(dev_labels, y_pred_dev, average='weighted'))\n",
        "    print(\"Macro F1 Train: \", f1_score(train_labels, y_pred_train, average='macro'))\n",
        "    print(\"Macro F1 Dev: \", f1_score(dev_labels, y_pred_dev, average='macro'))\n",
        "    print(\"Micro F1 Train: \", f1_score(train_labels, y_pred_train, average='micro'))\n",
        "    print(\"Micro F1 Dev: \", f1_score(dev_labels, y_pred_dev, average='micro'))\n",
        "    print(\"Weighted Recall Train: \", recall_score(train_labels, y_pred_train, average='weighted'))\n",
        "    print(\"Weighted Recall Dev: \", recall_score(dev_labels, y_pred_dev, average='weighted'))\n",
        "    print(\"Macro Recall Train: \", recall_score(train_labels, y_pred_train, average='macro'))\n",
        "    print(\"Macro Recall Dev: \", recall_score(dev_labels, y_pred_dev, average='macro'))\n",
        "    print(\"Micro Recall Train: \", recall_score(train_labels, y_pred_train, average='micro'))\n",
        "    print(\"Micro Recall Dev: \", recall_score(dev_labels, y_pred_dev, average='micro'))\n",
        "    # Confusion Matrix\n",
        "    print(\"Confusion Matrix Train: \")\n",
        "    print(confusion_matrix(train_labels, y_pred_train))\n",
        "    print(\"Confusion Matrix Dev: \")\n",
        "    print(confusion_matrix(dev_labels, y_pred_dev))"
      ],
      "metadata": {
        "id": "O-0Gp7t-rDo2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "computeAllScores(train_pred, val_pred, train_Y, val_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV_jxJygrzy_",
        "outputId": "54a6e95f-4a7d-414a-fe07-fcd46c84096b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train:  0.9910309667673716\n",
            "Accuracy Dev:  0.7050604229607251\n",
            "Weighted F1 Train:  0.9910206913928981\n",
            "Weighted F1 Dev:  0.6999076134016204\n",
            "Macro F1 Train:  0.989820129897951\n",
            "Macro F1 Dev:  0.6632554549725104\n",
            "Micro F1 Train:  0.9910309667673716\n",
            "Micro F1 Dev:  0.7050604229607251\n",
            "Weighted Recall Train:  0.9910309667673716\n",
            "Weighted Recall Dev:  0.7050604229607251\n",
            "Macro Recall Train:  0.9887099610201029\n",
            "Macro Recall Dev:  0.6591150883366599\n",
            "Micro Recall Train:  0.9910309667673716\n",
            "Micro Recall Dev:  0.7050604229607251\n",
            "Confusion Matrix Train: \n",
            "[[7075   32]\n",
            " [  63 3422]]\n",
            "Confusion Matrix Dev: \n",
            "[[1400  333]\n",
            " [ 448  467]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_pred = np.where(val_pred > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "XW70dHlDIH37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(val_Y, val_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTYFXI0AHgh_",
        "outputId": "fd1a044f-2375-4dbe-aeb6-56b8ce614888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6926490155178788"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_X)/len(val_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDoR2vp9Icyx",
        "outputId": "31e4557d-793f-4a6a-9daf-b796867799f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-pFAU0Fbytd",
        "outputId": "be2657a1-b4e8-4496-8a09-7a91cd16b7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2648"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "np414M7eb0aY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}