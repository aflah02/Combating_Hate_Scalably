{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pKJ-mNfNtDpH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import keras\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPool2D, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
        "from keras.layers import MaxPool1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_replacement = {\n",
        "    'OFF': 0,\n",
        "    'NOT': 1,\n",
        "}"
      ],
      "metadata": {
        "id": "GbDWzCkjDwzh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace labels with numbers\n",
        "train_labels = [label_replacement[label] for label in train_labels]\n",
        "dev_labels = [label_replacement[label] for label in dev_labels]\n",
        "test_labels = [label_replacement[label] for label in test_labels]"
      ],
      "metadata": {
        "id": "WBDb6GUFfTWG"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Processing parameters\n",
        "BATCH_SIZE = 32\n",
        "MAX_WORDS = 10000\n",
        "MAX_SEQ_LENGTH = 1000\n",
        "\n",
        "# Model Parameters\n",
        "EMBEDDING_DIM = 100\n",
        "filter_sizes = [3,4,5]\n",
        "num_filters = 256\n",
        "embedding_dim = 100\n",
        "\n",
        "# Drop out probabilities\n",
        "drop = 0.5\n",
        "batch_size = 32\n",
        "epochs = 2\n"
      ],
      "metadata": {
        "id": "yctwP5FbujYk"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df_train = pd.read_csv(\"train_preprocessed.csv\")\n",
        "df_test = pd.read_csv(\"test_preprocessed.csv\")\n",
        "df_val = pd.read_csv(\"val_preprocessed.csv\")\n",
        "\n",
        "df_train = df_train[['preprocessed_text', 'label']]\n",
        "df_test = df_test[['preprocessed_text', 'label']]\n",
        "df_val = df_val[['preprocessed_text', 'label']]\n",
        "\n",
        "df_train = df_train[df_train.preprocessed_text.notna()]\n",
        "df_val = df_val[df_train.preprocessed_text.notna()]\n",
        "df_test = df_test[df_train.preprocessed_text.notna()]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fkfrf5IjWD_",
        "outputId": "4a9a867e-4ce0-446e-e5ca-05604b773ed8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train['preprocessed_text'].values\n",
        "X_dev = df_val['preprocessed_text'].values\n",
        "X_test = df_test['preprocessed_text'].values"
      ],
      "metadata": {
        "id": "XxTj21tRskqY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map words to numbers for ref (tokenize)\n",
        "tokenizer = Tokenizer(num_words = MAX_WORDS)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "dev_sequences = tokenizer.texts_to_sequences(X_dev)\n",
        "\n",
        "train_sequences = pad_sequences(train_sequences, maxlen=MAX_SEQ_LENGTH)\n",
        "dev_sequences = pad_sequences(dev_sequences, maxlen=MAX_SEQ_LENGTH)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXWLr0SPDlA9",
        "outputId": "1b9d09c1-9737-4dd8-8b69-218d090db8dd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.convert_to_tensor(train_sequences, dtype=tf.int64)\n",
        "y_train = tf.convert_to_tensor(train_labels)\n",
        "\n",
        "X_dev = tf.convert_to_tensor(dev_sequences, dtype=tf.int64)\n",
        "y_dev = tf.convert_to_tensor(dev_labels)\n"
      ],
      "metadata": {
        "id": "9YOyUJCZf3Cc"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open(\"glove.6B.100d.txt\")\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coeff = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coeff\n",
        "f.close()\n",
        "\n",
        "print(len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4MC9Rb-xWfW",
        "outputId": "cef81478-4403-41b6-c505-23d53d85732d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(word_index)+1, EMBEDDING_DIM))\n",
        "# initializing matrix (id -> vector)\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None: \n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "OK9oOHxEx3K3"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom loss function\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "  y_true = tf.cast(y_true, tf.float32)\n",
        "  y_pred = tf.cast(y_pred, tf.float32)\n",
        "  y_pred = K.round(y_pred)\n",
        "  tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "  tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "  fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "  fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "  p = tp / (tp + fp + K.epsilon())\n",
        "  r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "  f1 = 2*p*r / (p+r+K.epsilon())\n",
        "  f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "  return K.mean(f1)\n",
        "  \n",
        "  \n",
        "def f1_loss(y_true, y_pred):\n",
        "  y_true = tf.cast(y_true, tf.float32)\n",
        "  y_pred = tf.cast(y_pred, tf.float32)\n",
        "  tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "  tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "  fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "  fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "  p = tp / (tp + fp + K.epsilon())\n",
        "  r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "  f1 = 2*p*r / (p+r+K.epsilon())\n",
        "  f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "  return 1 - K.mean(f1)"
      ],
      "metadata": {
        "id": "E4J1GPW052In"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQ_LENGTH,\n",
        "                            trainable=False)"
      ],
      "metadata": {
        "id": "Dy38Lm5nymx8"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(MAX_SEQ_LENGTH,), dtype='int32')\n",
        "embedding = embedding_layer(inputs)\n",
        "\n",
        "print(embedding.shape)\n",
        "reshape = Reshape((MAX_SEQ_LENGTH,EMBEDDING_DIM,1))(embedding)\n",
        "print(reshape.shape)\n",
        "\n",
        "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
        "\n",
        "maxpool_0 = MaxPool2D(pool_size=(MAX_SEQ_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
        "maxpool_1 = MaxPool2D(pool_size=(MAX_SEQ_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
        "maxpool_2 = MaxPool2D(pool_size=(MAX_SEQ_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
        "\n",
        "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
        "flatten = Flatten()(concatenated_tensor)\n",
        "dropout = Dropout(drop)(flatten)\n",
        "output = Dense(units=1, activation='softmax')(dropout)\n",
        "\n",
        "# this creates a model that includes\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "adam = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(optimizer=adam, loss=f1_loss, metrics=['accuracy', f1])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT_FkWuQ0Jca",
        "outputId": "84065aa5-c825-4391-d5f1-7bd3946fc340"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1000, 100)\n",
            "(None, 1000, 100, 1)\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 1000)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1000, 100)    1792800     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)            (None, 1000, 100, 1  0           ['embedding[5][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 998, 1, 256)  77056       ['reshape_5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 997, 1, 256)  102656      ['reshape_5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 996, 1, 256)  128256      ['reshape_5[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_15 (MaxPooling2D  (None, 1, 1, 256)   0           ['conv2d_15[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_16 (MaxPooling2D  (None, 1, 1, 256)   0           ['conv2d_16[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_17 (MaxPooling2D  (None, 1, 1, 256)   0           ['conv2d_17[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 3, 1, 256)    0           ['max_pooling2d_15[0][0]',       \n",
            "                                                                  'max_pooling2d_16[0][0]',       \n",
            "                                                                  'max_pooling2d_17[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)            (None, 768)          0           ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 768)          0           ['flatten_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            769         ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,101,537\n",
            "Trainable params: 308,737\n",
            "Non-trainable params: 1,792,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training model\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_dev, y_dev))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCO0DKpp6Rzu",
        "outputId": "99915361-a82d-42cd-ea1a-437b6cf3a2d6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "331/331 [==============================] - 362s 1s/step - loss: 0.2001 - accuracy: 0.6710 - f1: 0.7999 - val_loss: 0.2123 - val_accuracy: 0.6545 - val_f1: 0.7880\n",
            "Epoch 2/2\n",
            "331/331 [==============================] - 364s 1s/step - loss: 0.1998 - accuracy: 0.6710 - f1: 0.8002 - val_loss: 0.2123 - val_accuracy: 0.6545 - val_f1: 0.7880\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f61417ee5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_test_text = tokenizer.texts_to_sequences(X_test)\n",
        "tokenized_test_text = pad_sequences(tokenized_test_text, MAX_SEQ_LENGTH)\n",
        "X_test = tf.convert_to_tensor(tokenized_test_text, dtype=tf.int64)"
      ],
      "metadata": {
        "id": "hPj8j99X61xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "train_pred = model.predict(X_train)\n",
        "test_pred = model.predict(X_test)\n",
        "val_pred = model.predict(X_dev)\n",
        "\n",
        "# Convert predictions to labels\n",
        "train_pred = np.where(train_pred > 0.5, 1, 0)\n",
        "test_pred = np.where(test_pred > 0.5, 1, 0)\n",
        "val_pred = np.where(val_pred > 0.5, 1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FshPAwsR7qN0",
        "outputId": "17f98002-a2b9-4b5a-c0e1-936a62203670"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "331/331 [==============================] - 114s 344ms/step\n",
            "27/27 [==============================] - 9s 337ms/step\n",
            "83/83 [==============================] - 28s 339ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "computeAllScores(train_pred, val_pred, test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAHjEz25GlBk",
        "outputId": "f411b84f-8ca9-4e5c-ee60-8a75d4838c21"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Train:  0.6709780966767371\n",
            "Accuracy Dev:  0.6544561933534743\n",
            "Weighted F1 Train:  0.5388599732280435\n",
            "Weighted F1 Dev:  0.5177688121805848\n",
            "Macro F1 Train:  0.4015481100627154\n",
            "Macro F1 Dev:  0.39557178726318193\n",
            "Micro F1 Train:  0.6709780966767371\n",
            "Micro F1 Dev:  0.6544561933534743\n",
            "Weighted Recall Train:  0.6709780966767371\n",
            "Weighted Recall Dev:  0.6544561933534743\n",
            "Macro Recall Train:  0.5\n",
            "Macro Recall Dev:  0.5\n",
            "Micro Recall Train:  0.6709780966767371\n",
            "Micro Recall Dev:  0.6544561933534743\n",
            "Confusion Matrix Train: \n",
            "[[   0 3485]\n",
            " [   0 7107]]\n",
            "Confusion Matrix Dev: \n",
            "[[   0  915]\n",
            " [   0 1733]]\n"
          ]
        }
      ]
    }
  ]
}