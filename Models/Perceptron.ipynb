{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ip=127.0.0.1\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from embeddings_loader import *\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, dev_labels, _ = load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'NOT': 0,\n",
    "    'OFF': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace labels with numbers\n",
    "train_labels = [label_replacement[label] for label in train_labels]\n",
    "dev_labels = [label_replacement[label] for label in dev_labels]\n",
    "# test_labels = [label_replacement[label] for label in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(max_iter=1000)\n",
    "gridsearch = GridSearchCV(perceptron, param_grid = {\n",
    "\t'eta0': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "\t'alpha': [0.0001, 0.05],\n",
    "    'early_stopping': [True, False]\n",
    "}, scoring = \"f1_macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Twitter 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt25_train, gt25_dev, gt25_test = load_glove_twitter_25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "gt25_train = np.nan_to_num(gt25_train)\n",
    "gt25_dev = np.nan_to_num(gt25_dev)\n",
    "gt25_test = np.nan_to_num(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = gridsearch.fit(gt25_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "perceptron = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.05, 'early_stopping': True, 'eta0': 0.001, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = perceptron.fit(gt25_train, train_labels)\n",
    "save_model(perceptron, \"perceptron_gt25.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = perceptron.predict(gt25_train)\n",
    "dev_preds = perceptron.predict(gt25_dev)\n",
    "test_preds = perceptron.predict(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.6642749244712991\n",
      "Accuracy Dev:  0.6620090634441088\n",
      "Accuracy Test:  0.7093023255813954\n",
      "Weighted F1 Train:  0.6648779590343605\n",
      "Weighted F1 Dev:  0.6604994820482796\n",
      "Weighted F1 Test:  0.7193010097372466\n",
      "Macro F1 Train:  0.6211941352861997\n",
      "Macro F1 Dev:  0.6230801613880299\n",
      "Macro F1 Test:  0.6665301766924756\n",
      "Micro F1 Train:  0.6642749244712991\n",
      "Micro F1 Dev:  0.6620090634441088\n",
      "Micro F1 Test:  0.7093023255813953\n",
      "Weighted Recall Train:  0.6642749244712991\n",
      "Weighted Recall Dev:  0.6620090634441088\n",
      "Weighted Recall Test:  0.7093023255813954\n",
      "Macro Recall Train:  0.6216467729696045\n",
      "Macro Recall Dev:  0.6220972507323288\n",
      "Macro Recall Test:  0.684744623655914\n",
      "Micro Recall Train:  0.6642749244712991\n",
      "Micro Recall Dev:  0.6620090634441088\n",
      "Micro Recall Test:  0.7093023255813954\n",
      "Confusion Matrix Train: \n",
      "[[5304 1803]\n",
      " [1753 1732]]\n",
      "Confusion Matrix Dev: \n",
      "[[1302  431]\n",
      " [ 464  451]]\n",
      "Confusion Matrix Test: \n",
      "[[459 161]\n",
      " [ 89 151]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft300_train, ft300_dev, ft300_test = load_fasttext_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "ft300_train = np.nan_to_num(ft300_train)\n",
    "ft300_dev = np.nan_to_num(ft300_dev)\n",
    "ft300_test = np.nan_to_num(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = gridsearch.fit(ft300_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "perceptron = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001, 'early_stopping': True, 'eta0': 0.01, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = perceptron.fit(ft300_train, train_labels)\n",
    "save_model(perceptron, \"perceptron_ft300.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = perceptron.predict(ft300_train)\n",
    "dev_preds = perceptron.predict(ft300_dev)\n",
    "test_preds = perceptron.predict(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.6876888217522659\n",
      "Accuracy Dev:  0.6714501510574018\n",
      "Accuracy Test:  0.7430232558139535\n",
      "Weighted F1 Train:  0.5772865318196864\n",
      "Weighted F1 Dev:  0.5567151908973788\n",
      "Weighted F1 Test:  0.6577642270906181\n",
      "Macro F1 Train:  0.4558171836617875\n",
      "Macro F1 Dev:  0.44833967425661775\n",
      "Macro F1 Test:  0.5070738507423977\n",
      "Micro F1 Train:  0.6876888217522659\n",
      "Micro F1 Dev:  0.6714501510574018\n",
      "Micro F1 Test:  0.7430232558139535\n",
      "Weighted Recall Train:  0.6876888217522659\n",
      "Weighted Recall Dev:  0.6714501510574018\n",
      "Weighted Recall Test:  0.7430232558139535\n",
      "Macro Recall Train:  0.525979498863347\n",
      "Macro Recall Dev:  0.525106026064281\n",
      "Macro Recall Test:  0.5434139784946236\n",
      "Micro Recall Train:  0.6876888217522659\n",
      "Micro Recall Dev:  0.6714501510574018\n",
      "Micro Recall Test:  0.7430232558139535\n",
      "Confusion Matrix Train: \n",
      "[[7099    8]\n",
      " [3300  185]]\n",
      "Confusion Matrix Dev: \n",
      "[[1731    2]\n",
      " [ 868   47]]\n",
      "Confusion Matrix Test: \n",
      "[[617   3]\n",
      " [218  22]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v300_train, w2v300_dev, w2v300_test = load_word2vec_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "w2v300_train = np.nan_to_num(w2v300_train)\n",
    "w2v300_dev = np.nan_to_num(w2v300_dev)\n",
    "w2v300_test = np.nan_to_num(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = gridsearch.fit(w2v300_train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "perceptron = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.05, 'early_stopping': True, 'eta0': 0.0001, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = perceptron.fit(w2v300_train, train_labels)\n",
    "save_model(perceptron, \"perceptron_w2v300.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = perceptron.predict(w2v300_train)\n",
    "dev_preds = perceptron.predict(w2v300_dev)\n",
    "test_preds = perceptron.predict(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.7302681268882175\n",
      "Accuracy Dev:  0.7145015105740181\n",
      "Accuracy Test:  0.7883720930232558\n",
      "Weighted F1 Train:  0.6774233816683244\n",
      "Weighted F1 Dev:  0.6571334989434339\n",
      "Weighted F1 Test:  0.7569970254191454\n",
      "Macro F1 Train:  0.5989470933589953\n",
      "Macro F1 Dev:  0.5858158188312484\n",
      "Macro F1 Test:  0.6693313953488372\n",
      "Micro F1 Train:  0.7302681268882174\n",
      "Micro F1 Dev:  0.7145015105740181\n",
      "Micro F1 Test:  0.7883720930232558\n",
      "Weighted Recall Train:  0.7302681268882175\n",
      "Weighted Recall Dev:  0.7145015105740181\n",
      "Weighted Recall Test:  0.7883720930232558\n",
      "Macro Recall Train:  0.6053822700718006\n",
      "Macro Recall Dev:  0.5995238680830803\n",
      "Macro Recall Test:  0.6502016129032258\n",
      "Micro Recall Train:  0.7302681268882175\n",
      "Micro Recall Dev:  0.7145015105740181\n",
      "Micro Recall Test:  0.7883720930232558\n",
      "Confusion Matrix Train: \n",
      "[[6898  209]\n",
      " [2648  837]]\n",
      "Confusion Matrix Dev: \n",
      "[[1684   49]\n",
      " [ 707  208]]\n",
      "Confusion Matrix Test: \n",
      "[[597  23]\n",
      " [159  81]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = gridsearch.fit(train, train_labels)\n",
    "best_params = grid_results.best_params_\n",
    "perceptron = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.05, 'early_stopping': True, 'eta0': 0.0001, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = perceptron.fit(train, train_labels)\n",
    "save_model(perceptron, \"perceptron_better_no_pca.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = perceptron.predict(train)\n",
    "dev_preds = perceptron.predict(dev)\n",
    "test_preds = perceptron.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.7553814199395771\n",
      "Accuracy Dev:  0.7292296072507553\n",
      "Accuracy Test:  0.7383720930232558\n",
      "Weighted F1 Train:  0.7451591918833306\n",
      "Weighted F1 Dev:  0.7199455155362555\n",
      "Weighted F1 Test:  0.739509717429957\n",
      "Macro F1 Train:  0.7020568519302173\n",
      "Macro F1 Dev:  0.6821624955240131\n",
      "Macro F1 Test:  0.6777529639233202\n",
      "Micro F1 Train:  0.7553814199395771\n",
      "Micro F1 Dev:  0.7292296072507554\n",
      "Micro F1 Test:  0.7383720930232558\n",
      "Weighted Recall Train:  0.7553814199395771\n",
      "Weighted Recall Dev:  0.7292296072507553\n",
      "Weighted Recall Test:  0.7383720930232558\n",
      "Macro Recall Train:  0.6915849126459879\n",
      "Macro Recall Dev:  0.6747429360627359\n",
      "Macro Recall Test:  0.6793682795698924\n",
      "Micro Recall Train:  0.7553814199395771\n",
      "Micro Recall Dev:  0.7292296072507553\n",
      "Micro Recall Test:  0.7383720930232558\n",
      "Confusion Matrix Train: \n",
      "[[6241  866]\n",
      " [1725 1760]]\n",
      "Confusion Matrix Dev: \n",
      "[[1475  258]\n",
      " [ 459  456]]\n",
      "Confusion Matrix Test: \n",
      "[[504 116]\n",
      " [109 131]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20d1fca357f405521ace12b74f8f225b4b452b0790d4cac507474c909b88285c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
